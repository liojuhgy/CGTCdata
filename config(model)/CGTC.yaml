embedding_size: 64
feat_embed_dim: 64
mm_image_weight: [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
aggr_mode: ['add']
knn_k: [5, 10, 20]
n_mm_layers: [1, 2]
u_layers: [1, 2]
dropout: [0.1]
learning_rate: 0.0001
reg_weight: [0.1, 0.01, 0.001, 0.0001, 0.00001]
hyper_parameters: ["mm_image_weight","k", "u_layers", "n_mm_layers", "knn_k", "aggr_mode", "reg_weight", "learning_rate"]
gpu_id: 0
use_gpu: True
seed: [0, 42, 100, 2024, 4096]

# multi-modal raw features
data_path: '../data/'
inter_splitting_label: 'x_label'
filter_out_cod_start_users: True
is_multimodal_model: True

checkpoint_dir: 'saved'
save_recommended_topk: True
recommend_topk: 'recommend_topk/'
embedding_size: 64
epochs: 1000
stopping_step: 20
learner: adam
learning_rate_scheduler: [1.0, 50]
eval_step: 1

training_neg_sample_num: 1
use_neg_sampling: True
use_full_sampling: False
NEG_PREFIX: neg__

USER_ID_FIELD: user_id:token
ITEM_ID_FIELD: item_id:token
TIME_FIELD: timestamp:float
field_separator: "\t"
# evaluation settings
metrics: ["Recall", "NDCG"]
topk: [10, 20]
valid_metric: Recall@20
#
use_raw_features: False
max_txt_len: 32
max_img_size: 256
vocab_size: 30522
type_vocab_size: 2
hidden_size: 4
pad_token_id: 0
max_position_embeddings: 512
layer_norm_eps: 1e-12
hidden_dropout_prob: 0.1

end2end: False
       
